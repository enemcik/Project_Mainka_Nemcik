{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from gensim.utils import deaccent\n",
    "import random\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6db5c84e7bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSlider\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHoverTool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSelect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayouts\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwidgetbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrate_limiter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRateLimiter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "#geocoding\n",
    "from bokeh.io import output_notebook, show, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar, NumeralTickFormatter\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "from bokeh.io.doc import curdoc\n",
    "from bokeh.models import Slider, HoverTool, Select\n",
    "from bokeh.layouts import widgetbox, row, column\n",
    "import geopy\n",
    "import geopandas as gpd\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8569757b7911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplugins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from ipywidgets import interact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "#visualisation\n",
    "import folium\n",
    "import folium.plugins as plugins\n",
    "#from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    " def get_soups(links, name):\n",
    "        '''\n",
    "        This function iterates over all search pages, converts them into a BeautifulSoup object and stores them in a JSON file as \n",
    "        outside of this script. The keys of the dictoniary distinguish here between the different objects/HTML-pages. \n",
    "        '''\n",
    "        count = 0\n",
    "        dict_ = {}\n",
    "        soups = []\n",
    "        for link in links:\n",
    "            sleep(random.uniform(0.5, 2))\n",
    "            request = requests.get(link)\n",
    "            request.encoding='UTF-8'\n",
    "            soups.append(BeautifulSoup(request.text,'lxml'))\n",
    "        for soup in soups:\n",
    "            dict_[count] = str(deaccent(soup).encode(\"utf-8\"))\n",
    "            count += 1\n",
    "        with open(name, 'w') as write_file:\n",
    "            json.dump(dict_, write_file, indent = 4)\n",
    "        \n",
    "        '''\n",
    "        with open(name, 'w') as f:\n",
    "            for s in soups:\n",
    "                f.write(str(deaccent(s).encode(\"utf-8\")))\n",
    "            f.close\n",
    "            \n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "'''Create a new Folder \"Data\" in the current working directory to store & access the data files which will be produced throughout this script'''\n",
    "newfolder = r'Data' \n",
    "if not os.path.exists(newfolder): #if already exists will not be created again\n",
    "    os.makedirs(newfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloaderBezRealitky(): #error prone, need to correct\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        For the bezrealitky search, you need to iterate over search pages. Self.page_bezrealitky stores the maximum amount\n",
    "        of pages and then via self.link a list of all pages from search is created in self.hrefs_bezrealitky.\n",
    "        '''\n",
    "        self.link = 'https://www.bezrealitky.cz/vypis/nabidka-pronajem/byt/praha?_token=pr1lf-vKwDFfmFbICiz2PfC-Zdwq-2JolXi4MeMHsrw&page=1'\n",
    "        self.request = requests.get(self.link)\n",
    "        self.request.encoding='UTF-8'\n",
    "        self.soup = BeautifulSoup(self.request.text,'lxml')\n",
    "        self.page_bezrealitky = int(self.soup.findAll('a',{'class':'page-link pagination__page'})[-2].text)\n",
    "        self.hrefs_bezrealitky = ['https://www.bezrealitky.cz/vypis/nabidka-pronajem/byt/praha?_token=pr1lf-vKwDFfmFbICiz2PfC-Zdwq-2JolXi4MeMHsrw&page=' \n",
    "                                  + str(i) for i in range(1,self.page_bezrealitky)]\n",
    "        self.soups = []\n",
    "        self.counter = counter\n",
    "\n",
    "    def get_data(self):\n",
    "        '''\n",
    "        Main method to obtain and transform the data. HTMLs are read from the JSON file and stored in a list (soup_list) \n",
    "        within this script. Next, the method iterates over the list, converts the strings in the list into a BeautifulSoup\n",
    "        object and parses the html for relevant data. At the end, a nested dictionary (dicts) is created and stored\n",
    "        as a json file outside of this script.\n",
    "        '''\n",
    "        with open(fileDir + '\\\\Data\\\\bezrealitky_links.json', 'r', encoding='utf-8') as f:\n",
    "            content = json.load(f)\n",
    "        soup_list = list(content.values())\n",
    "        dicts = {}\n",
    "        counter = 0\n",
    "        for soup in soup_list:\n",
    "            descrips = [] #empty list for apartment values\n",
    "            values = [] #empty list for apartment prices\n",
    "            vals = BeautifulSoup(soup,'lxml').findAll('strong', {'class':'product__value'}) #parsing for apartment values\n",
    "            ##vals = soup.findAll('strong', {'class':'product__value'})\n",
    "            for vl in vals:\n",
    "                values.append(vl.text.strip())\n",
    "            #img = soup.findAll('img')\n",
    "            img = BeautifulSoup(soup,'lxml').findAll('img') #parsing for apartment info (street, city, size..)\n",
    "            for i in img:\n",
    "                if 'Pronajem' and 'obr. c. 1' in i['alt']: #info present at all pictures, let's take info from the first one\n",
    "                        info = i['alt'].split(',')[0:4] #info separated by comma, split into a list\n",
    "                        if 'Praha' == info[-1].strip(): #if street non present, insert a NaN instead\n",
    "                            info.insert(2, 'NaN')\n",
    "                            del info[-1]\n",
    "                            m = info[1].split(' ')\n",
    "                            info[1] = m[1]\n",
    "                            descrips.append(info)\n",
    "                        else:\n",
    "                            m = info[1].split(' ')\n",
    "                            info[1] = m[1]\n",
    "                            descrips.append(info)\n",
    "            count = 0\n",
    "            for pp in values: #append apartment prices to info about apartments in list descrips\n",
    "                try:\n",
    "                    descrips[count].append(pp)\n",
    "                    descrips[count][0] = descrips[count][0][-4:].strip()\n",
    "                    count += 1\n",
    "                except IndexError:\n",
    "                    count += 1\n",
    "                    continue\n",
    "            for item in descrips:\n",
    "                try:\n",
    "                    if '+' in item[4]: #prices often written as '19000 Kč + 4000Kč' so we need to split it\n",
    "                        prices = item.pop(4).split('+')\n",
    "                        item.append(re.sub(\"[^0-9]\", \"\", prices[0])) #keep only numeric characters, i.e. price\n",
    "                        item.append(re.sub(\"[^0-9]\", \"\", prices[1]))\n",
    "                    else:\n",
    "                        prices = [item.pop(4), '0'] #if only '19000 Kč', insert 0 as price for utilities not specified\n",
    "                        item.append(re.sub(\"[^0-9]\", \"\", prices[0]))\n",
    "                        item.append(re.sub(\"[^0-9]\", \"\", prices[1]))\n",
    "                except IndexError:\n",
    "                    continue\n",
    "            for item in descrips: #store apartment info, price into a dictionary and index by counter\n",
    "                try:\n",
    "                    dict = {}\n",
    "                    dict['Size'] = item[0]\n",
    "                    dict['m2'] = re.sub(\"[^0-9]\", \"\", item[1]) #keep only size, i.e. numeric characters\n",
    "                    dict['Street'] = deaccent(item[2]) #deaccent to provent potential errors\n",
    "                    dict['District'] = deaccent(item[3])\n",
    "                    dict['Base Price'] = int(item[4])\n",
    "                    dict['Utilities Price'] = int(item[5])\n",
    "                    dict['Total Price'] = int(item[4]) + int(item[5])\n",
    "                    dict['Source'] = 'bezrealitky.cz'\n",
    "                    dicts[self.counter] = dict\n",
    "                    self.counter += 1\n",
    "                except IndexError:\n",
    "                    #counter +=1\n",
    "                    continue\n",
    "            print('Done loop number ' + str(self.counter) + '. Printing descrips.')\n",
    "        with open(fileDir + '\\\\Data\\\\bezrealitky.json', 'w') as write_file: #store data into a json file\n",
    "            json.dump(dicts, write_file, indent = 4)\n",
    "\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = DownloaderBezRealitky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_soups(a.hrefs_bezrealitky, fileDir + '\\\\Data\\\\bezrealitky_links.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loop number 10. Printing descrips.\n",
      "Done loop number 20. Printing descrips.\n",
      "Done loop number 30. Printing descrips.\n",
      "Done loop number 40. Printing descrips.\n",
      "Done loop number 50. Printing descrips.\n",
      "Done loop number 60. Printing descrips.\n",
      "Done loop number 70. Printing descrips.\n",
      "Done loop number 80. Printing descrips.\n",
      "Done loop number 90. Printing descrips.\n",
      "Done loop number 100. Printing descrips.\n",
      "Done loop number 110. Printing descrips.\n",
      "Done loop number 120. Printing descrips.\n",
      "Done loop number 130. Printing descrips.\n",
      "Done loop number 140. Printing descrips.\n",
      "Done loop number 150. Printing descrips.\n",
      "Done loop number 160. Printing descrips.\n",
      "Done loop number 170. Printing descrips.\n",
      "Done loop number 180. Printing descrips.\n",
      "Done loop number 190. Printing descrips.\n",
      "Done loop number 200. Printing descrips.\n",
      "Done loop number 210. Printing descrips.\n",
      "Done loop number 220. Printing descrips.\n",
      "Done loop number 230. Printing descrips.\n",
      "Done loop number 240. Printing descrips.\n",
      "Done loop number 250. Printing descrips.\n",
      "Done loop number 260. Printing descrips.\n",
      "Done loop number 270. Printing descrips.\n",
      "Done loop number 280. Printing descrips.\n",
      "Done loop number 290. Printing descrips.\n",
      "Done loop number 300. Printing descrips.\n",
      "Done loop number 310. Printing descrips.\n",
      "Done loop number 320. Printing descrips.\n",
      "Done loop number 330. Printing descrips.\n",
      "Done loop number 340. Printing descrips.\n",
      "Done loop number 350. Printing descrips.\n",
      "Done loop number 360. Printing descrips.\n",
      "Done loop number 370. Printing descrips.\n",
      "Done loop number 380. Printing descrips.\n",
      "Done loop number 390. Printing descrips.\n",
      "Done loop number 400. Printing descrips.\n",
      "Done loop number 410. Printing descrips.\n",
      "Done loop number 420. Printing descrips.\n",
      "Done loop number 430. Printing descrips.\n",
      "Done loop number 440. Printing descrips.\n",
      "Done loop number 450. Printing descrips.\n",
      "Done loop number 460. Printing descrips.\n",
      "Done loop number 470. Printing descrips.\n",
      "Done loop number 480. Printing descrips.\n",
      "Done loop number 490. Printing descrips.\n",
      "Done loop number 500. Printing descrips.\n",
      "Done loop number 510. Printing descrips.\n",
      "Done loop number 520. Printing descrips.\n",
      "Done loop number 530. Printing descrips.\n",
      "Done loop number 540. Printing descrips.\n",
      "Done loop number 550. Printing descrips.\n",
      "Done loop number 560. Printing descrips.\n",
      "Done loop number 570. Printing descrips.\n",
      "Done loop number 580. Printing descrips.\n",
      "Done loop number 590. Printing descrips.\n",
      "Done loop number 600. Printing descrips.\n",
      "Done loop number 610. Printing descrips.\n",
      "Done loop number 620. Printing descrips.\n",
      "Done loop number 630. Printing descrips.\n",
      "Done loop number 640. Printing descrips.\n",
      "Done loop number 650. Printing descrips.\n",
      "Done loop number 660. Printing descrips.\n",
      "Done loop number 670. Printing descrips.\n",
      "Done loop number 680. Printing descrips.\n",
      "Done loop number 690. Printing descrips.\n",
      "Done loop number 700. Printing descrips.\n",
      "Done loop number 710. Printing descrips.\n",
      "Done loop number 720. Printing descrips.\n",
      "Done loop number 730. Printing descrips.\n",
      "Done loop number 740. Printing descrips.\n",
      "Done loop number 750. Printing descrips.\n",
      "Done loop number 760. Printing descrips.\n",
      "Done loop number 770. Printing descrips.\n",
      "Done loop number 780. Printing descrips.\n",
      "Done loop number 790. Printing descrips.\n",
      "Done loop number 800. Printing descrips.\n",
      "Done loop number 810. Printing descrips.\n",
      "Done loop number 820. Printing descrips.\n",
      "Done loop number 830. Printing descrips.\n",
      "Done loop number 840. Printing descrips.\n",
      "Done loop number 850. Printing descrips.\n",
      "Done loop number 860. Printing descrips.\n",
      "Done loop number 870. Printing descrips.\n",
      "Done loop number 880. Printing descrips.\n",
      "Done loop number 890. Printing descrips.\n",
      "Done loop number 900. Printing descrips.\n",
      "Done loop number 910. Printing descrips.\n",
      "Done loop number 920. Printing descrips.\n",
      "Done loop number 930. Printing descrips.\n",
      "Done loop number 940. Printing descrips.\n",
      "Done loop number 950. Printing descrips.\n",
      "Done loop number 960. Printing descrips.\n",
      "Done loop number 970. Printing descrips.\n",
      "Done loop number 980. Printing descrips.\n",
      "Done loop number 990. Printing descrips.\n",
      "Done loop number 1000. Printing descrips.\n",
      "Done loop number 1010. Printing descrips.\n",
      "Done loop number 1020. Printing descrips.\n",
      "Done loop number 1030. Printing descrips.\n",
      "Done loop number 1040. Printing descrips.\n",
      "Done loop number 1050. Printing descrips.\n",
      "Done loop number 1060. Printing descrips.\n",
      "Done loop number 1070. Printing descrips.\n",
      "Done loop number 1080. Printing descrips.\n",
      "Done loop number 1090. Printing descrips.\n",
      "Done loop number 1100. Printing descrips.\n",
      "Done loop number 1110. Printing descrips.\n",
      "Done loop number 1120. Printing descrips.\n",
      "Done loop number 1130. Printing descrips.\n",
      "Done loop number 1140. Printing descrips.\n",
      "Done loop number 1150. Printing descrips.\n",
      "Done loop number 1160. Printing descrips.\n",
      "Done loop number 1170. Printing descrips.\n",
      "Done loop number 1180. Printing descrips.\n",
      "Done loop number 1190. Printing descrips.\n",
      "Done loop number 1200. Printing descrips.\n",
      "Done loop number 1210. Printing descrips.\n",
      "Done loop number 1220. Printing descrips.\n",
      "Done loop number 1230. Printing descrips.\n",
      "Done loop number 1240. Printing descrips.\n",
      "Done loop number 1250. Printing descrips.\n",
      "Done loop number 1260. Printing descrips.\n",
      "Done loop number 1270. Printing descrips.\n",
      "Done loop number 1280. Printing descrips.\n",
      "Done loop number 1290. Printing descrips.\n",
      "Done loop number 1300. Printing descrips.\n",
      "Done loop number 1310. Printing descrips.\n",
      "Done loop number 1320. Printing descrips.\n",
      "Done loop number 1330. Printing descrips.\n",
      "Done loop number 1340. Printing descrips.\n",
      "Done loop number 1350. Printing descrips.\n",
      "Done loop number 1360. Printing descrips.\n",
      "Done loop number 1370. Printing descrips.\n",
      "Done loop number 1380. Printing descrips.\n",
      "Done loop number 1390. Printing descrips.\n",
      "Done loop number 1400. Printing descrips.\n",
      "Done loop number 1410. Printing descrips.\n",
      "Done loop number 1420. Printing descrips.\n",
      "Done loop number 1430. Printing descrips.\n",
      "Done loop number 1440. Printing descrips.\n",
      "Done loop number 1450. Printing descrips.\n",
      "Done loop number 1460. Printing descrips.\n",
      "Done loop number 1470. Printing descrips.\n",
      "Done loop number 1480. Printing descrips.\n",
      "Done loop number 1490. Printing descrips.\n",
      "Done loop number 1500. Printing descrips.\n",
      "Done loop number 1510. Printing descrips.\n",
      "Done loop number 1520. Printing descrips.\n",
      "Done loop number 1530. Printing descrips.\n",
      "Done loop number 1540. Printing descrips.\n",
      "Done loop number 1550. Printing descrips.\n",
      "Done loop number 1560. Printing descrips.\n",
      "Done loop number 1570. Printing descrips.\n",
      "Done loop number 1580. Printing descrips.\n",
      "Done loop number 1590. Printing descrips.\n",
      "Done loop number 1600. Printing descrips.\n",
      "Done loop number 1610. Printing descrips.\n",
      "Done loop number 1620. Printing descrips.\n",
      "Done loop number 1630. Printing descrips.\n",
      "Done loop number 1640. Printing descrips.\n",
      "Done loop number 1650. Printing descrips.\n",
      "Done loop number 1660. Printing descrips.\n",
      "Done loop number 1670. Printing descrips.\n",
      "Done loop number 1680. Printing descrips.\n",
      "Done loop number 1690. Printing descrips.\n",
      "Done loop number 1700. Printing descrips.\n",
      "Done loop number 1710. Printing descrips.\n",
      "Done loop number 1720. Printing descrips.\n",
      "Done loop number 1730. Printing descrips.\n",
      "Done loop number 1740. Printing descrips.\n",
      "Done loop number 1750. Printing descrips.\n",
      "Done loop number 1760. Printing descrips.\n",
      "Done loop number 1770. Printing descrips.\n",
      "Done loop number 1780. Printing descrips.\n",
      "Done loop number 1790. Printing descrips.\n",
      "Done loop number 1800. Printing descrips.\n",
      "Done loop number 1810. Printing descrips.\n",
      "Done loop number 1820. Printing descrips.\n",
      "Done loop number 1830. Printing descrips.\n",
      "Done loop number 1840. Printing descrips.\n",
      "Done loop number 1850. Printing descrips.\n",
      "Done loop number 1860. Printing descrips.\n",
      "Done loop number 1870. Printing descrips.\n",
      "Done loop number 1880. Printing descrips.\n",
      "Done loop number 1890. Printing descrips.\n",
      "Done loop number 1900. Printing descrips.\n",
      "Done loop number 1910. Printing descrips.\n",
      "Done loop number 1920. Printing descrips.\n",
      "Done loop number 1930. Printing descrips.\n",
      "Done loop number 1940. Printing descrips.\n",
      "Done loop number 1950. Printing descrips.\n",
      "Done loop number 1960. Printing descrips.\n",
      "Done loop number 1970. Printing descrips.\n",
      "Done loop number 1980. Printing descrips.\n",
      "Done loop number 1990. Printing descrips.\n",
      "Done loop number 2000. Printing descrips.\n",
      "Done loop number 2010. Printing descrips.\n",
      "Done loop number 2020. Printing descrips.\n",
      "Done loop number 2030. Printing descrips.\n",
      "Done loop number 2040. Printing descrips.\n",
      "Done loop number 2050. Printing descrips.\n",
      "Done loop number 2060. Printing descrips.\n",
      "Done loop number 2070. Printing descrips.\n",
      "Done loop number 2080. Printing descrips.\n",
      "Done loop number 2090. Printing descrips.\n",
      "Done loop number 2100. Printing descrips.\n",
      "Done loop number 2110. Printing descrips.\n",
      "Done loop number 2120. Printing descrips.\n",
      "Done loop number 2130. Printing descrips.\n",
      "Done loop number 2140. Printing descrips.\n",
      "Done loop number 2150. Printing descrips.\n",
      "Done loop number 2160. Printing descrips.\n",
      "Done loop number 2170. Printing descrips.\n",
      "Done loop number 2180. Printing descrips.\n",
      "Done loop number 2190. Printing descrips.\n",
      "Done loop number 2200. Printing descrips.\n",
      "Done loop number 2210. Printing descrips.\n",
      "Done loop number 2220. Printing descrips.\n",
      "Done loop number 2230. Printing descrips.\n",
      "Done loop number 2240. Printing descrips.\n",
      "Done loop number 2250. Printing descrips.\n",
      "Done loop number 2260. Printing descrips.\n",
      "Done loop number 2270. Printing descrips.\n",
      "Done loop number 2280. Printing descrips.\n",
      "Done loop number 2290. Printing descrips.\n",
      "Done loop number 2300. Printing descrips.\n",
      "Done loop number 2310. Printing descrips.\n",
      "Done loop number 2320. Printing descrips.\n",
      "Done loop number 2330. Printing descrips.\n",
      "Done loop number 2340. Printing descrips.\n",
      "Done loop number 2350. Printing descrips.\n",
      "Done loop number 2360. Printing descrips.\n",
      "Done loop number 2370. Printing descrips.\n",
      "Done loop number 2380. Printing descrips.\n",
      "Done loop number 2390. Printing descrips.\n",
      "Done loop number 2400. Printing descrips.\n",
      "Done loop number 2410. Printing descrips.\n",
      "Done loop number 2420. Printing descrips.\n",
      "Done loop number 2430. Printing descrips.\n",
      "Done loop number 2440. Printing descrips.\n",
      "Done loop number 2450. Printing descrips.\n",
      "Done loop number 2460. Printing descrips.\n",
      "Done loop number 2470. Printing descrips.\n",
      "Done loop number 2480. Printing descrips.\n",
      "Done loop number 2490. Printing descrips.\n",
      "Done loop number 2500. Printing descrips.\n",
      "Done loop number 2510. Printing descrips.\n",
      "Done loop number 2520. Printing descrips.\n",
      "Done loop number 2530. Printing descrips.\n",
      "Done loop number 2540. Printing descrips.\n",
      "Done loop number 2550. Printing descrips.\n",
      "Done loop number 2560. Printing descrips.\n",
      "Done loop number 2570. Printing descrips.\n",
      "Done loop number 2580. Printing descrips.\n",
      "Done loop number 2590. Printing descrips.\n",
      "Done loop number 2600. Printing descrips.\n",
      "Done loop number 2610. Printing descrips.\n",
      "Done loop number 2620. Printing descrips.\n",
      "Done loop number 2630. Printing descrips.\n",
      "Done loop number 2640. Printing descrips.\n",
      "Done loop number 2650. Printing descrips.\n",
      "Done loop number 2660. Printing descrips.\n",
      "Done loop number 2670. Printing descrips.\n",
      "Done loop number 2680. Printing descrips.\n",
      "Done loop number 2690. Printing descrips.\n",
      "Done loop number 2700. Printing descrips.\n",
      "Done loop number 2710. Printing descrips.\n",
      "Done loop number 2720. Printing descrips.\n",
      "Done loop number 2730. Printing descrips.\n",
      "Done loop number 2740. Printing descrips.\n",
      "Done loop number 2750. Printing descrips.\n",
      "Done loop number 2760. Printing descrips.\n",
      "Done loop number 2770. Printing descrips.\n",
      "Done loop number 2780. Printing descrips.\n",
      "Done loop number 2790. Printing descrips.\n",
      "Done loop number 2800. Printing descrips.\n",
      "Done loop number 2810. Printing descrips.\n",
      "Done loop number 2820. Printing descrips.\n",
      "Done loop number 2830. Printing descrips.\n",
      "Done loop number 2840. Printing descrips.\n",
      "Done loop number 2850. Printing descrips.\n",
      "Done loop number 2860. Printing descrips.\n",
      "Done loop number 2870. Printing descrips.\n",
      "Done loop number 2880. Printing descrips.\n",
      "Done loop number 2890. Printing descrips.\n",
      "Done loop number 2900. Printing descrips.\n",
      "Done loop number 2910. Printing descrips.\n",
      "Done loop number 2920. Printing descrips.\n"
     ]
    }
   ],
   "source": [
    "a.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = a.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloaderReality():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        For the reality search, you need to iterate over search pages. Self.page_reality stores the maximum amount\n",
    "        of pages and then via self.link a list of all pages from search is created in self.hrefs_reality.\n",
    "        '''\n",
    "        self.link = 'https://reality.idnes.cz/s/pronajem/byty/praha/?page=1'\n",
    "        self.request = requests.get(self.link)\n",
    "        self.request.encoding='UTF-8'\n",
    "        self.soup = BeautifulSoup(self.request.text,'lxml')\n",
    "        self.page_reality = int(self.soup.findAll('a',{'class':'btn btn--border paging__item'})[-1].text) - 1\n",
    "        self.hrefs_reality = ['https://reality.idnes.cz/s/pronajem/byty/praha/?page=' \n",
    "                                  + str(i) for i in range(1,self.page_reality)]\n",
    "        self.soups = []\n",
    "        self.counter = counter\n",
    "        \n",
    "    def get_data(self):\n",
    "        '''\n",
    "        Main method to obtain and transform the data. HTMLs are read from the JSON file and stored in a list (soup_list) \n",
    "        within this script. Next, the method iterates over the list, converts the strings in txt file into a BeautifulSoup\n",
    "        object and parses the html for relevant data. At the end, a nested dictionary (dicts) is created and stored\n",
    "        as a json file outside of this script.\n",
    "        '''\n",
    "        '''\n",
    "        with open(fileDir + '\\\\Data\\\\reality_idnes_links.txt', 'r') as f:\n",
    "            content = f.read()\n",
    "        soup_list = content.split('BREAKHERE')\n",
    "        '''\n",
    "        with open(fileDir + '\\\\Data\\\\reality_idnes_links.json', 'r', encoding='utf-8') as f:\n",
    "            content = json.load(f)\n",
    "        soup_list = list(content.values())\n",
    "        dicts = {}\n",
    "        counter = 0\n",
    "        for soup in soup_list:\n",
    "            descrips = [] #empty list for apartment values\n",
    "            values = [] #empty list for apartment prices\n",
    "            info_size = []\n",
    "            apartments = []\n",
    "            vals = BeautifulSoup(soup,'lxml').findAll('p', {'class':'c-list-products__price'}) #parsing for apartment values\n",
    "            for vl in vals: #adding values\n",
    "                values.append(re.sub(\"[^0-9]\", \"\",vl.find('strong').text))\n",
    "                \n",
    "            locs = BeautifulSoup(soup,'lxml').findAll('p', {'class':'c-list-products__info'})\n",
    "            for i in locs: #adding location\n",
    "                if 'Komercni sdeleni' in i.text:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp_info = str(i.text)\n",
    "                    temp_info = re.sub(r'^(?:\\\\n)+','', temp_info).strip()[:-2]\n",
    "                    temp_info = temp_info.strip().split(',')\n",
    "                    temp_info = [i.strip() for i in temp_info]\n",
    "                    if len(temp_info) == 1:\n",
    "                        temp_info.append(temp_info[0])\n",
    "                        temp_info[0] = 'NaN'\n",
    "                    if len(temp_info) == 3:\n",
    "                        del temp_info[2]\n",
    "                    descrips.append(temp_info)\n",
    "                    \n",
    "            sizes = BeautifulSoup(soup,'lxml').findAll('h2', {'class':'c-list-products__title'})\n",
    "            for s in sizes: #adding size and m2\n",
    "                try:\n",
    "                    item = s.text.split('bytu')[1].strip()[:-2]\n",
    "                    temp = item.split(',')\n",
    "                    temp[1] = temp[1][:-10].strip()\n",
    "                    info_size.append(temp)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "            \n",
    "            for apart in range(0,len(info_size)):\n",
    "                apartments.append(info_size[apart] + descrips[apart] + [values[apart]])\n",
    "                \n",
    "            for item in apartments: #store apartment info, price into a dictionary and index by counter\n",
    "                try:\n",
    "                    dict = {}\n",
    "                    dict['Size'] = item[0]\n",
    "                    dict['m2'] = item[1]\n",
    "                    dict['Street'] = deaccent(item[2]) #deaccent to provent potential errors\n",
    "                    dict['District'] = deaccent(item[3])\n",
    "                    dict['Base Price'] = int(item[4])\n",
    "                    dict['Utilities Price'] = 0\n",
    "                    dict['Total Price'] = int(item[4])\n",
    "                    dict['Source'] = 'reality.idnes.cz'\n",
    "                    dicts[self.counter] = dict\n",
    "                    self.counter +=1\n",
    "                except ValueError:\n",
    "                    #counter += 1\n",
    "                    continue\n",
    "            print('Done loop number ' + str(self.counter) + '. Printing apartments.')\n",
    "        with open(fileDir + '\\\\Data\\\\idnes_reality.json', 'w') as write_file: #store data into a json file\n",
    "            json.dump(dicts, write_file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = DownloaderReality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_soups(b.hrefs_reality, fileDir + '\\\\Data\\\\reality_idnes_links.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loop number 2939. Printing apartments.\n",
      "Done loop number 2959. Printing apartments.\n",
      "Done loop number 2979. Printing apartments.\n",
      "Done loop number 2999. Printing apartments.\n",
      "Done loop number 3019. Printing apartments.\n",
      "Done loop number 3039. Printing apartments.\n",
      "Done loop number 3059. Printing apartments.\n",
      "Done loop number 3079. Printing apartments.\n",
      "Done loop number 3099. Printing apartments.\n",
      "Done loop number 3119. Printing apartments.\n",
      "Done loop number 3139. Printing apartments.\n",
      "Done loop number 3159. Printing apartments.\n",
      "Done loop number 3179. Printing apartments.\n",
      "Done loop number 3199. Printing apartments.\n",
      "Done loop number 3219. Printing apartments.\n",
      "Done loop number 3238. Printing apartments.\n",
      "Done loop number 3257. Printing apartments.\n",
      "Done loop number 3277. Printing apartments.\n",
      "Done loop number 3297. Printing apartments.\n",
      "Done loop number 3316. Printing apartments.\n",
      "Done loop number 3336. Printing apartments.\n",
      "Done loop number 3355. Printing apartments.\n",
      "Done loop number 3375. Printing apartments.\n",
      "Done loop number 3394. Printing apartments.\n",
      "Done loop number 3413. Printing apartments.\n",
      "Done loop number 3433. Printing apartments.\n",
      "Done loop number 3453. Printing apartments.\n",
      "Done loop number 3473. Printing apartments.\n",
      "Done loop number 3493. Printing apartments.\n",
      "Done loop number 3513. Printing apartments.\n",
      "Done loop number 3533. Printing apartments.\n",
      "Done loop number 3553. Printing apartments.\n",
      "Done loop number 3573. Printing apartments.\n",
      "Done loop number 3593. Printing apartments.\n",
      "Done loop number 3613. Printing apartments.\n",
      "Done loop number 3633. Printing apartments.\n",
      "Done loop number 3653. Printing apartments.\n",
      "Done loop number 3673. Printing apartments.\n",
      "Done loop number 3693. Printing apartments.\n",
      "Done loop number 3712. Printing apartments.\n",
      "Done loop number 3732. Printing apartments.\n",
      "Done loop number 3752. Printing apartments.\n",
      "Done loop number 3771. Printing apartments.\n",
      "Done loop number 3791. Printing apartments.\n",
      "Done loop number 3811. Printing apartments.\n",
      "Done loop number 3831. Printing apartments.\n",
      "Done loop number 3851. Printing apartments.\n",
      "Done loop number 3871. Printing apartments.\n",
      "Done loop number 3891. Printing apartments.\n",
      "Done loop number 3911. Printing apartments.\n",
      "Done loop number 3931. Printing apartments.\n",
      "Done loop number 3951. Printing apartments.\n",
      "Done loop number 3971. Printing apartments.\n",
      "Done loop number 3991. Printing apartments.\n",
      "Done loop number 4011. Printing apartments.\n",
      "Done loop number 4031. Printing apartments.\n",
      "Done loop number 4051. Printing apartments.\n",
      "Done loop number 4071. Printing apartments.\n",
      "Done loop number 4091. Printing apartments.\n",
      "Done loop number 4111. Printing apartments.\n",
      "Done loop number 4131. Printing apartments.\n",
      "Done loop number 4151. Printing apartments.\n",
      "Done loop number 4171. Printing apartments.\n",
      "Done loop number 4190. Printing apartments.\n",
      "Done loop number 4210. Printing apartments.\n",
      "Done loop number 4230. Printing apartments.\n",
      "Done loop number 4249. Printing apartments.\n",
      "Done loop number 4269. Printing apartments.\n",
      "Done loop number 4289. Printing apartments.\n",
      "Done loop number 4309. Printing apartments.\n",
      "Done loop number 4329. Printing apartments.\n",
      "Done loop number 4349. Printing apartments.\n",
      "Done loop number 4369. Printing apartments.\n",
      "Done loop number 4389. Printing apartments.\n",
      "Done loop number 4409. Printing apartments.\n",
      "Done loop number 4429. Printing apartments.\n",
      "Done loop number 4449. Printing apartments.\n",
      "Done loop number 4469. Printing apartments.\n",
      "Done loop number 4489. Printing apartments.\n",
      "Done loop number 4509. Printing apartments.\n",
      "Done loop number 4529. Printing apartments.\n",
      "Done loop number 4549. Printing apartments.\n",
      "Done loop number 4569. Printing apartments.\n",
      "Done loop number 4589. Printing apartments.\n",
      "Done loop number 4609. Printing apartments.\n",
      "Done loop number 4629. Printing apartments.\n",
      "Done loop number 4649. Printing apartments.\n",
      "Done loop number 4669. Printing apartments.\n",
      "Done loop number 4689. Printing apartments.\n",
      "Done loop number 4709. Printing apartments.\n",
      "Done loop number 4729. Printing apartments.\n",
      "Done loop number 4749. Printing apartments.\n",
      "Done loop number 4769. Printing apartments.\n",
      "Done loop number 4788. Printing apartments.\n",
      "Done loop number 4808. Printing apartments.\n",
      "Done loop number 4828. Printing apartments.\n",
      "Done loop number 4848. Printing apartments.\n",
      "Done loop number 4868. Printing apartments.\n",
      "Done loop number 4888. Printing apartments.\n",
      "Done loop number 4908. Printing apartments.\n",
      "Done loop number 4928. Printing apartments.\n",
      "Done loop number 4948. Printing apartments.\n",
      "Done loop number 4968. Printing apartments.\n",
      "Done loop number 4987. Printing apartments.\n",
      "Done loop number 5007. Printing apartments.\n",
      "Done loop number 5025. Printing apartments.\n",
      "Done loop number 5045. Printing apartments.\n",
      "Done loop number 5065. Printing apartments.\n",
      "Done loop number 5085. Printing apartments.\n",
      "Done loop number 5105. Printing apartments.\n",
      "Done loop number 5124. Printing apartments.\n",
      "Done loop number 5144. Printing apartments.\n",
      "Done loop number 5164. Printing apartments.\n",
      "Done loop number 5184. Printing apartments.\n",
      "Done loop number 5204. Printing apartments.\n",
      "Done loop number 5224. Printing apartments.\n",
      "Done loop number 5244. Printing apartments.\n",
      "Done loop number 5264. Printing apartments.\n",
      "Done loop number 5284. Printing apartments.\n",
      "Done loop number 5304. Printing apartments.\n",
      "Done loop number 5324. Printing apartments.\n",
      "Done loop number 5344. Printing apartments.\n",
      "Done loop number 5364. Printing apartments.\n",
      "Done loop number 5384. Printing apartments.\n",
      "Done loop number 5404. Printing apartments.\n",
      "Done loop number 5423. Printing apartments.\n",
      "Done loop number 5443. Printing apartments.\n",
      "Done loop number 5463. Printing apartments.\n",
      "Done loop number 5483. Printing apartments.\n",
      "Done loop number 5503. Printing apartments.\n",
      "Done loop number 5523. Printing apartments.\n",
      "Done loop number 5543. Printing apartments.\n",
      "Done loop number 5563. Printing apartments.\n",
      "Done loop number 5583. Printing apartments.\n",
      "Done loop number 5603. Printing apartments.\n",
      "Done loop number 5623. Printing apartments.\n",
      "Done loop number 5643. Printing apartments.\n",
      "Done loop number 5663. Printing apartments.\n",
      "Done loop number 5683. Printing apartments.\n",
      "Done loop number 5703. Printing apartments.\n",
      "Done loop number 5721. Printing apartments.\n",
      "Done loop number 5741. Printing apartments.\n",
      "Done loop number 5761. Printing apartments.\n",
      "Done loop number 5781. Printing apartments.\n",
      "Done loop number 5801. Printing apartments.\n",
      "Done loop number 5821. Printing apartments.\n",
      "Done loop number 5841. Printing apartments.\n",
      "Done loop number 5861. Printing apartments.\n",
      "Done loop number 5881. Printing apartments.\n",
      "Done loop number 5901. Printing apartments.\n",
      "Done loop number 5921. Printing apartments.\n",
      "Done loop number 5941. Printing apartments.\n",
      "Done loop number 5961. Printing apartments.\n",
      "Done loop number 5981. Printing apartments.\n",
      "Done loop number 6001. Printing apartments.\n",
      "Done loop number 6021. Printing apartments.\n",
      "Done loop number 6041. Printing apartments.\n",
      "Done loop number 6061. Printing apartments.\n",
      "Done loop number 6081. Printing apartments.\n",
      "Done loop number 6101. Printing apartments.\n",
      "Done loop number 6121. Printing apartments.\n",
      "Done loop number 6141. Printing apartments.\n",
      "Done loop number 6161. Printing apartments.\n",
      "Done loop number 6181. Printing apartments.\n",
      "Done loop number 6201. Printing apartments.\n",
      "Done loop number 6221. Printing apartments.\n",
      "Done loop number 6241. Printing apartments.\n",
      "Done loop number 6261. Printing apartments.\n",
      "Done loop number 6281. Printing apartments.\n",
      "Done loop number 6301. Printing apartments.\n",
      "Done loop number 6321. Printing apartments.\n",
      "Done loop number 6341. Printing apartments.\n",
      "Done loop number 6361. Printing apartments.\n",
      "Done loop number 6380. Printing apartments.\n",
      "Done loop number 6398. Printing apartments.\n",
      "Done loop number 6418. Printing apartments.\n",
      "Done loop number 6438. Printing apartments.\n",
      "Done loop number 6458. Printing apartments.\n",
      "Done loop number 6478. Printing apartments.\n",
      "Done loop number 6498. Printing apartments.\n",
      "Done loop number 6518. Printing apartments.\n",
      "Done loop number 6538. Printing apartments.\n",
      "Done loop number 6558. Printing apartments.\n",
      "Done loop number 6578. Printing apartments.\n",
      "Done loop number 6598. Printing apartments.\n",
      "Done loop number 6618. Printing apartments.\n",
      "Done loop number 6638. Printing apartments.\n",
      "Done loop number 6658. Printing apartments.\n",
      "Done loop number 6678. Printing apartments.\n",
      "Done loop number 6697. Printing apartments.\n",
      "Done loop number 6717. Printing apartments.\n",
      "Done loop number 6737. Printing apartments.\n",
      "Done loop number 6757. Printing apartments.\n",
      "Done loop number 6777. Printing apartments.\n",
      "Done loop number 6797. Printing apartments.\n",
      "Done loop number 6817. Printing apartments.\n",
      "Done loop number 6837. Printing apartments.\n",
      "Done loop number 6857. Printing apartments.\n",
      "Done loop number 6877. Printing apartments.\n",
      "Done loop number 6897. Printing apartments.\n",
      "Done loop number 6917. Printing apartments.\n",
      "Done loop number 6937. Printing apartments.\n",
      "Done loop number 6957. Printing apartments.\n",
      "Done loop number 6977. Printing apartments.\n",
      "Done loop number 6995. Printing apartments.\n",
      "Done loop number 7015. Printing apartments.\n",
      "Done loop number 7035. Printing apartments.\n",
      "Done loop number 7055. Printing apartments.\n",
      "Done loop number 7075. Printing apartments.\n",
      "Done loop number 7095. Printing apartments.\n",
      "Done loop number 7115. Printing apartments.\n",
      "Done loop number 7135. Printing apartments.\n",
      "Done loop number 7155. Printing apartments.\n",
      "Done loop number 7175. Printing apartments.\n",
      "Done loop number 7195. Printing apartments.\n",
      "Done loop number 7215. Printing apartments.\n",
      "Done loop number 7234. Printing apartments.\n",
      "Done loop number 7254. Printing apartments.\n",
      "Done loop number 7274. Printing apartments.\n",
      "Done loop number 7294. Printing apartments.\n",
      "Done loop number 7314. Printing apartments.\n",
      "Done loop number 7334. Printing apartments.\n",
      "Done loop number 7354. Printing apartments.\n",
      "Done loop number 7374. Printing apartments.\n",
      "Done loop number 7394. Printing apartments.\n",
      "Done loop number 7414. Printing apartments.\n",
      "Done loop number 7433. Printing apartments.\n",
      "Done loop number 7453. Printing apartments.\n",
      "Done loop number 7473. Printing apartments.\n",
      "Done loop number 7493. Printing apartments.\n",
      "Done loop number 7513. Printing apartments.\n",
      "Done loop number 7533. Printing apartments.\n",
      "Done loop number 7552. Printing apartments.\n",
      "Done loop number 7572. Printing apartments.\n",
      "Done loop number 7592. Printing apartments.\n",
      "Done loop number 7612. Printing apartments.\n",
      "Done loop number 7632. Printing apartments.\n",
      "Done loop number 7652. Printing apartments.\n",
      "Done loop number 7672. Printing apartments.\n",
      "Done loop number 7692. Printing apartments.\n",
      "Done loop number 7712. Printing apartments.\n",
      "Done loop number 7732. Printing apartments.\n",
      "Done loop number 7752. Printing apartments.\n",
      "Done loop number 7772. Printing apartments.\n",
      "Done loop number 7791. Printing apartments.\n",
      "Done loop number 7811. Printing apartments.\n",
      "Done loop number 7831. Printing apartments.\n",
      "Done loop number 7851. Printing apartments.\n",
      "Done loop number 7871. Printing apartments.\n",
      "Done loop number 7891. Printing apartments.\n",
      "Done loop number 7911. Printing apartments.\n",
      "Done loop number 7931. Printing apartments.\n",
      "Done loop number 7951. Printing apartments.\n",
      "Done loop number 7971. Printing apartments.\n",
      "Done loop number 7991. Printing apartments.\n",
      "Done loop number 8010. Printing apartments.\n",
      "Done loop number 8029. Printing apartments.\n",
      "Done loop number 8049. Printing apartments.\n",
      "Done loop number 8069. Printing apartments.\n",
      "Done loop number 8089. Printing apartments.\n",
      "Done loop number 8109. Printing apartments.\n",
      "Done loop number 8129. Printing apartments.\n",
      "Done loop number 8149. Printing apartments.\n",
      "Done loop number 8168. Printing apartments.\n",
      "Done loop number 8188. Printing apartments.\n",
      "Done loop number 8208. Printing apartments.\n",
      "Done loop number 8228. Printing apartments.\n",
      "Done loop number 8248. Printing apartments.\n",
      "Done loop number 8268. Printing apartments.\n",
      "Done loop number 8288. Printing apartments.\n",
      "Done loop number 8308. Printing apartments.\n",
      "Done loop number 8328. Printing apartments.\n",
      "Done loop number 8348. Printing apartments.\n",
      "Done loop number 8368. Printing apartments.\n",
      "Done loop number 8388. Printing apartments.\n",
      "Done loop number 8408. Printing apartments.\n",
      "Done loop number 8428. Printing apartments.\n",
      "Done loop number 8448. Printing apartments.\n",
      "Done loop number 8468. Printing apartments.\n",
      "Done loop number 8488. Printing apartments.\n",
      "Done loop number 8508. Printing apartments.\n",
      "Done loop number 8528. Printing apartments.\n",
      "Done loop number 8548. Printing apartments.\n",
      "Done loop number 8568. Printing apartments.\n",
      "Done loop number 8588. Printing apartments.\n",
      "Done loop number 8608. Printing apartments.\n",
      "Done loop number 8628. Printing apartments.\n",
      "Done loop number 8648. Printing apartments.\n",
      "Done loop number 8668. Printing apartments.\n",
      "Done loop number 8688. Printing apartments.\n",
      "Done loop number 8707. Printing apartments.\n",
      "Done loop number 8726. Printing apartments.\n",
      "Done loop number 8746. Printing apartments.\n",
      "Done loop number 8765. Printing apartments.\n",
      "Done loop number 8784. Printing apartments.\n",
      "Done loop number 8804. Printing apartments.\n",
      "Done loop number 8824. Printing apartments.\n",
      "Done loop number 8844. Printing apartments.\n",
      "Done loop number 8864. Printing apartments.\n",
      "Done loop number 8884. Printing apartments.\n",
      "Done loop number 8903. Printing apartments.\n",
      "Done loop number 8923. Printing apartments.\n",
      "Done loop number 8943. Printing apartments.\n",
      "Done loop number 8963. Printing apartments.\n",
      "Done loop number 8983. Printing apartments.\n",
      "Done loop number 9003. Printing apartments.\n",
      "Done loop number 9023. Printing apartments.\n",
      "Done loop number 9043. Printing apartments.\n",
      "Done loop number 9062. Printing apartments.\n",
      "Done loop number 9082. Printing apartments.\n",
      "Done loop number 9102. Printing apartments.\n",
      "Done loop number 9122. Printing apartments.\n",
      "Done loop number 9142. Printing apartments.\n",
      "Done loop number 9162. Printing apartments.\n",
      "Done loop number 9182. Printing apartments.\n",
      "Done loop number 9202. Printing apartments.\n",
      "Done loop number 9222. Printing apartments.\n",
      "Done loop number 9241. Printing apartments.\n",
      "Done loop number 9260. Printing apartments.\n",
      "Done loop number 9280. Printing apartments.\n",
      "Done loop number 9300. Printing apartments.\n",
      "Done loop number 9320. Printing apartments.\n",
      "Done loop number 9339. Printing apartments.\n",
      "Done loop number 9359. Printing apartments.\n",
      "Done loop number 9379. Printing apartments.\n",
      "Done loop number 9398. Printing apartments.\n",
      "Done loop number 9418. Printing apartments.\n",
      "Done loop number 9438. Printing apartments.\n"
     ]
    }
   ],
   "source": [
    "b.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloaderCeskeReality():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        For the reality search, you need to iterate over search pages. Self.page_reality stores the maximum amount\n",
    "        of pages and then via self.link a list of all pages from search is created in self.hrefs_reality.\n",
    "        '''\n",
    "        self.link = 'https://www.ceskereality.cz/pronajem/byty/praha/?strana=2'\n",
    "\n",
    "        self.request = requests.get(self.link)\n",
    "        self.request.encoding='UTF-8'\n",
    "        self.soup = BeautifulSoup(self.request.text, 'html.parser')\n",
    "        \n",
    "        self.page_ceskereality = int([page.text for page in self.soup.findAll('ul',{'class':'pages'})[0]][-2]) - 1\n",
    "        self.hrefs_reality = ['https://www.ceskereality.cz/pronajem/byty/praha/?strana=' \n",
    "                        + str(i) for i in range(1,self.page_ceskereality)]\n",
    "        self.soups = []\n",
    "        \n",
    "    def get_soups(self):\n",
    "        '''\n",
    "        This method iterates over all search pages, converts them into a BeautifulSoup object and stores them in a txt file as \n",
    "        strings outside of this script. BREAKHERE is used to distinguish between objects. \n",
    "        '''\n",
    "        for link in self.hrefs_reality[0:3]:\n",
    "            sleep(random.uniform(0.5, 2))\n",
    "            self.link = link\n",
    "            self.request = requests.get(self.link)\n",
    "            self.request.encoding='utf-8'\n",
    "            self.soups.append(BeautifulSoup(self.request.text,'html.parser'))\n",
    "            print('Page saved.')\n",
    "            print(self.soups)\n",
    "        with open('ceske_reality_links.txt', 'w') as f:\n",
    "            for s in self.soups:\n",
    "                f.write(str(deaccent(s).encode(\"utf-8\")) + 'BREAKHERE')\n",
    "            f.close\n",
    "    \n",
    "    def get_data(self):\n",
    "        '''\n",
    "        Main method to obtain and transform the data. HTMLs are read from the txt file and stored in a list (soup_list) \n",
    "        within this script. Next, the method iterates over the list, converts the strings in txt file into a BeautifulSoup\n",
    "        object and parses the html for relevant data. At the end, a nested dictionary (dicts) is created and stored\n",
    "        as a json file outside of this script.\n",
    "        '''\n",
    "        with open('ceske_reality_links.txt', 'r') as f:\n",
    "            content = f.read()\n",
    "        soup_list = content.split('BREAKHERE')\n",
    "        dicts = {}\n",
    "        #counter = 0\n",
    "        for soup in soup_list[0:1]:\n",
    "            descrips = [] #empty list for apartment values\n",
    "            values = [] #empty list for apartment prices\n",
    "            info_size = []\n",
    "            apartments = []\n",
    "            vals = BeautifulSoup(soup,'lxml').findAll('div', {'class':'cena'}) #parsing for apartment values\n",
    "            for value in vals:\n",
    "                values.append(re.sub(\"[^0-9]\", \"\",value.text.split(',')[0]))\n",
    "            locs = BeautifulSoup(soup,'lxml').findAll('div', {'class':'div_nemovitost suda'})\n",
    "            for item in locs:\n",
    "                print(item.text)\n",
    "            #print(locs)\n",
    "\n",
    "            '''\n",
    "            for item in apartments: #store apartment info, price into a dictionary and index by counter\n",
    "                try:\n",
    "                    dict = {}\n",
    "                    dict['Size'] = item[0]\n",
    "                    dict['m2'] = item[1]\n",
    "                    dict['Street'] = deaccent(item[2]) #deaccent to provent potential errors\n",
    "                    dict['District'] = deaccent(item[3])\n",
    "                    dict['Base Price'] = int(item[4])\n",
    "                    dict['Utilities Price'] = 0\n",
    "                    dict['Total Price'] = int(item[4]) \n",
    "                    dicts[counter] = dict\n",
    "                    counter +=1\n",
    "                except ValueError:\n",
    "                    counter += 1\n",
    "                    continue\n",
    "            print('Done loop number ' + str(counter) + '. Printing apartments.')\n",
    "        with open('idnes_reality.json', 'w') as write_file: #store data into a json file\n",
    "            json.dump(dicts, write_file, indent = 4)      \n",
    "            '''          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DownloaderCeskeReality()\n",
    "c.get_soups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_soups(c.hrefs_reality[0:2], 'blah.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the fetched data into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = []\n",
    "data = {}\n",
    "def data_combine(*args):\n",
    "    #input example - 'idnes_reality.json', 'bezrealitky.json'\n",
    "    for arg in args:\n",
    "        with open(fileDir + '\\\\Data\\\\' + arg) as json_file:\n",
    "            file_ = json.load(json_file)\n",
    "            big_dict.append(file_)\n",
    "    for dt in big_dict:\n",
    "        data.update(dt)\n",
    "\n",
    "data_combine('bezrealitky.json', 'idnes_reality.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (removed) duplicates: 826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>m2</th>\n",
       "      <th>Street</th>\n",
       "      <th>District</th>\n",
       "      <th>Base Price</th>\n",
       "      <th>Utilities Price</th>\n",
       "      <th>Total Price</th>\n",
       "      <th>Source</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2+kk</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "      <td>Praha - Kunratice</td>\n",
       "      <td>16500</td>\n",
       "      <td>3900</td>\n",
       "      <td>20400</td>\n",
       "      <td>bezrealitky.cz</td>\n",
       "      <td>,Praha - Kunratice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2+kk</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "      <td>Praha - Kunratice</td>\n",
       "      <td>16000</td>\n",
       "      <td>3500</td>\n",
       "      <td>19500</td>\n",
       "      <td>bezrealitky.cz</td>\n",
       "      <td>,Praha - Kunratice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2+kk</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "      <td>Praha - Kunratice</td>\n",
       "      <td>26000</td>\n",
       "      <td>4000</td>\n",
       "      <td>30000</td>\n",
       "      <td>bezrealitky.cz</td>\n",
       "      <td>,Praha - Kunratice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2+kk</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "      <td>Praha - Kunratice</td>\n",
       "      <td>14500</td>\n",
       "      <td>3481</td>\n",
       "      <td>17981</td>\n",
       "      <td>bezrealitky.cz</td>\n",
       "      <td>,Praha - Kunratice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2+kk</td>\n",
       "      <td>65</td>\n",
       "      <td>Severni \\xe2\\x85\\xa2</td>\n",
       "      <td>Praha - Zabehlice</td>\n",
       "      <td>14000</td>\n",
       "      <td>1850</td>\n",
       "      <td>15850</td>\n",
       "      <td>bezrealitky.cz</td>\n",
       "      <td>Severni \\xe2\\x85\\xa2,Praha - Zabehlice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8607</th>\n",
       "      <td>3+kk</td>\n",
       "      <td>105</td>\n",
       "      <td>Na bateriich</td>\n",
       "      <td>Praha 6 - Stresovice</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>reality.idnes.cz</td>\n",
       "      <td>Na bateriich,Praha 6 - Stresovice,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8608</th>\n",
       "      <td>4+1</td>\n",
       "      <td>160</td>\n",
       "      <td>Ke Klimentce</td>\n",
       "      <td>Praha 5 - Smichov</td>\n",
       "      <td>42500</td>\n",
       "      <td>0</td>\n",
       "      <td>42500</td>\n",
       "      <td>reality.idnes.cz</td>\n",
       "      <td>Ke Klimentce,Praha 5 - Smichov,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8609</th>\n",
       "      <td>2+1</td>\n",
       "      <td>58</td>\n",
       "      <td>Horejsi nabrezi</td>\n",
       "      <td>Praha 5 - Smichov</td>\n",
       "      <td>36000</td>\n",
       "      <td>0</td>\n",
       "      <td>36000</td>\n",
       "      <td>reality.idnes.cz</td>\n",
       "      <td>Horejsi nabrezi,Praha 5 - Smichov,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>3+1</td>\n",
       "      <td>134</td>\n",
       "      <td>Horejsi nabrezi</td>\n",
       "      <td>Praha 5 - Smichov</td>\n",
       "      <td>42000</td>\n",
       "      <td>0</td>\n",
       "      <td>42000</td>\n",
       "      <td>reality.idnes.cz</td>\n",
       "      <td>Horejsi nabrezi,Praha 5 - Smichov,Praha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>3+kk</td>\n",
       "      <td>145</td>\n",
       "      <td>Povltavska</td>\n",
       "      <td>Praha 7 - Troja</td>\n",
       "      <td>48000</td>\n",
       "      <td>0</td>\n",
       "      <td>48000</td>\n",
       "      <td>reality.idnes.cz</td>\n",
       "      <td>Povltavska,Praha 7 - Troja,Praha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8612 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Size   m2                Street              District  Base Price  \\\n",
       "0     2+kk   69                           Praha - Kunratice       16500   \n",
       "1     2+kk   69                           Praha - Kunratice       16000   \n",
       "2     2+kk   69                           Praha - Kunratice       26000   \n",
       "3     2+kk   69                           Praha - Kunratice       14500   \n",
       "4     2+kk   65  Severni \\xe2\\x85\\xa2     Praha - Zabehlice       14000   \n",
       "...    ...  ...                   ...                   ...         ...   \n",
       "8607  3+kk  105          Na bateriich  Praha 6 - Stresovice       30000   \n",
       "8608   4+1  160          Ke Klimentce     Praha 5 - Smichov       42500   \n",
       "8609   2+1   58       Horejsi nabrezi     Praha 5 - Smichov       36000   \n",
       "8610   3+1  134       Horejsi nabrezi     Praha 5 - Smichov       42000   \n",
       "8611  3+kk  145            Povltavska       Praha 7 - Troja       48000   \n",
       "\n",
       "      Utilities Price  Total Price            Source  \\\n",
       "0                3900        20400    bezrealitky.cz   \n",
       "1                3500        19500    bezrealitky.cz   \n",
       "2                4000        30000    bezrealitky.cz   \n",
       "3                3481        17981    bezrealitky.cz   \n",
       "4                1850        15850    bezrealitky.cz   \n",
       "...               ...          ...               ...   \n",
       "8607                0        30000  reality.idnes.cz   \n",
       "8608                0        42500  reality.idnes.cz   \n",
       "8609                0        36000  reality.idnes.cz   \n",
       "8610                0        42000  reality.idnes.cz   \n",
       "8611                0        48000  reality.idnes.cz   \n",
       "\n",
       "                                           Address  \n",
       "0                         ,Praha - Kunratice,Praha  \n",
       "1                         ,Praha - Kunratice,Praha  \n",
       "2                         ,Praha - Kunratice,Praha  \n",
       "3                         ,Praha - Kunratice,Praha  \n",
       "4     Severni \\xe2\\x85\\xa2,Praha - Zabehlice,Praha  \n",
       "...                                            ...  \n",
       "8607       Na bateriich,Praha 6 - Stresovice,Praha  \n",
       "8608          Ke Klimentce,Praha 5 - Smichov,Praha  \n",
       "8609       Horejsi nabrezi,Praha 5 - Smichov,Praha  \n",
       "8610       Horejsi nabrezi,Praha 5 - Smichov,Praha  \n",
       "8611              Povltavska,Praha 7 - Troja,Praha  \n",
       "\n",
       "[8612 rows x 9 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_dataframe(data_file):\n",
    "    '''\n",
    "    The clean_dataframe function takes a data file (here a dictoniary) as an input and returns a pandas dataframe, which is cleaned up and ready to use. \n",
    "    In particular, NaN values are replaced with nothing, white spaces before and after strings in the columns which have strings are removed \n",
    "    (which is important for the duplicate search), Rows which are duplicates (ergo same flat) are removed, the removal is executed based on the columns\n",
    "    Size, m2, Street and Total Price as it is highly likely that in case each of these values is identical the flat is identical and a new column 'Address'\n",
    "    is created which is necessary for geocoding.\n",
    "    '''\n",
    "    df = pd.DataFrame(data_file).T\n",
    "    df = df.replace('NaN', '', regex=True)\n",
    "    for name in ['Size','Street','District']: #strips all white spaces before and after strings\n",
    "        df[name]=df[name].str.strip()\n",
    "    print('Number of (removed) duplicates: ' + str(df.duplicated(['Size', 'm2', 'Street', 'Total Price']).sum()))\n",
    "    df = df.drop_duplicates(['Size', 'm2', 'Street', 'Total Price'], ignore_index=True) #drops duplicates \n",
    "    df['Address'] = df['Street'] + ',' + df['District'] + ',' + 'Praha' #creating address column for geocoding\n",
    "    return df\n",
    "\n",
    "dataframe = clean_dataframe(data)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = geopy.Nominatim(user_agent='myGeocoder')\n",
    "#locator = geopy.GoogleV3(api_key='AIzaSyDgWSTfwvVV3AELge6lJCw8hT0T4TwejYc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the GPS addresses\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1) #this process takes about 2,5 hours\n",
    "\n",
    "dataframe['location'] = dataframe['Address'].apply(geocode)\n",
    "\n",
    "dataframe['point'] = dataframe['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "\n",
    "dataframe[['latitude', 'longitude', 'altitude']] = pd.DataFrame(dataframe['point'].tolist(), index=dataframe.index)\n",
    "\n",
    "dataframe = dataframe.dropna()\n",
    "dataframe.to_pickle('geo_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_pickle('geo_df.pkl') #load from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation - Apartment locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folium_map = folium.Map(location=[50.08804, 14.42076], #need to add popups with apartment info\n",
    "                        zoom_start=12,\n",
    "                        tiles='cartodbpositron')\n",
    "\n",
    "plugins.FastMarkerCluster(data=list(zip(dataframe['latitude'].values, dataframe['longitude'].values))).add_to(folium_map)\n",
    "\n",
    "popup = folium.Popup(dataframe['Base Price'])\n",
    "popup.add_to(folium_map)                          \n",
    "\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisations - Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Praha.json') as data: #could be automated to get the data?\n",
    "    hoods = json.loads(data.read()) #available at @PrahaOpenData\n",
    "    \n",
    "gdf = gpd.GeoDataFrame.from_features(hoods[\"features\"]) #converting to geodataframe\n",
    "#gdf.crs = {'init': 'epsg:4326'}\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_indv = gpd.GeoDataFrame(dataframe, geometry = gpd.points_from_xy(dataframe.longitude, dataframe.latitude))\n",
    "print(gdf_indv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = gpd.sjoin(gdf_indv, gdf, op='within') #geomerging polygons and points\n",
    "df_final = df_final.loc(axis=1)['Size', 'm2', 'Street', 'District', 'Base Price', 'Address', 'location', 'latitude',\n",
    "       'longitude', 'geometry', 'index_right', 'OBJECTID', 'PLOCHA', 'ID', 'NAZEV_MC',\n",
    "       'KOD_MO', 'TID_TMMESTSKECASTI_P', 'NAZEV_1', 'Shape_Length', 'Shape_Area']\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"m2\"] = df_final['m2'].apply(pd.to_numeric)\n",
    "avg_prices = df_final.loc(axis=1)['NAZEV_MC','Base Price','m2', 'District'].groupby(['NAZEV_MC']).mean()\n",
    "avg_prices['Median Price'] = df_final.loc(axis=1)['NAZEV_MC','Base Price'].groupby(['NAZEV_MC']).median()\n",
    "avg_prices['Price per Square Metre'] = avg_prices['Base Price'] / avg_prices['m2']\n",
    "\n",
    "\n",
    "avg_prices.columns = ['Price', 'm2', 'Median_price', 'Avg_m2']\n",
    "#avg_prices[\"AvgPrice/m2\"] = avg_prices['AvgPrice/m2'].apply(pd.to_numeric)\n",
    "avg_prices = avg_prices.round()\n",
    "avg_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GeoDataframe object with the neighborhood summary data (neighborhood)\n",
    "merged = pd.merge(gdf, avg_prices, on='NAZEV_MC', how='left')\n",
    "print(merged.head())\n",
    "#merged = merged.replace('NaN', '0', regex=True)\n",
    "# Fill the null values\n",
    "values = {'Price': 0, 'm2': 0}\n",
    "#          'sf_mean': 0, 'price_sf_mean': 0, 'min_income': 0}\n",
    "merged = merged.fillna(value=values)\n",
    "\n",
    "# Convert to json\n",
    "merged_json = json.loads(merged.to_json())\n",
    "\n",
    "# Convert to json preferred string-like object \n",
    "json_data = json.dumps(merged_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary contains the formatting for the data in the plots\n",
    "format_data = [('Price', 10000, 25000,'0,0', 'Price'),\n",
    "              ('Median_price', 10000, 25000,'0,0', 'Median Price'),\n",
    "              ('Avg_m2', 180, 350,'0,0', 'Price per Square Metre')] #more options to be added later\n",
    " \n",
    "#Create a DataFrame object from the dictionary \n",
    "format_df = pd.DataFrame(format_data, columns = ['field' , 'min_range', 'max_range' , 'format', 'verbage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plotting function\n",
    "def make_plot(field_name):    \n",
    "  # Set the format of the colorbar\n",
    "  min_range = format_df.loc[format_df['field'] == field_name, 'min_range'].iloc[0]\n",
    "  max_range = format_df.loc[format_df['field'] == field_name, 'max_range'].iloc[0]\n",
    "  field_format = format_df.loc[format_df['field'] == field_name, 'format'].iloc[0]\n",
    "\n",
    "  # Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "  color_mapper = LinearColorMapper(palette = palette, low = min_range, high = max_range)\n",
    "\n",
    "  # Create color bar.\n",
    "  format_tick = NumeralTickFormatter(format=field_format)\n",
    "  color_bar = ColorBar(color_mapper=color_mapper, label_standoff=18, formatter=format_tick,\n",
    "  border_line_color=None, location = (0, 0))\n",
    "\n",
    "  # Create figure object.\n",
    "  verbage = format_df.loc[format_df['field'] == field_name, 'verbage'].iloc[0]\n",
    "\n",
    "  p = figure(title = 'Apartment Rental ' + verbage + ' by City Parts in Prague', \n",
    "             plot_height = 650, plot_width = 850,\n",
    "             toolbar_location = None)\n",
    "  p.xgrid.grid_line_color = None\n",
    "  p.ygrid.grid_line_color = None\n",
    "  p.axis.visible = False\n",
    "\n",
    "  # Add patch renderer to figure. \n",
    "  p.patches('xs','ys', source = geosource, fill_color = {'field' : field_name, 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)\n",
    "  \n",
    "  # Specify color bar layout.\n",
    "  p.add_layout(color_bar, 'right')\n",
    "\n",
    "  # Add the hover tool to the graph\n",
    "  p.add_tools(hover)\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback function: update_plot\n",
    "def update_plot(attr, old, new):\n",
    "    # The input yr is the year selected from the slider\n",
    "    #yr = slider.value\n",
    "    new_data = json_data\n",
    "    \n",
    "    # The input cr is the criteria selected from the select box\n",
    "    cr = select.value\n",
    "    input_field = format_df.loc[format_df['verbage'] == cr, 'field'].iloc[0]\n",
    "    \n",
    "    # Update the plot based on the changed inputs\n",
    "    p = make_plot(input_field)\n",
    "    \n",
    "    # Update the layout, clear the old document and display the new document\n",
    "    layout = column(p, widgetbox(select))\n",
    "    #layout = column(p, widgetbox(select), widgetbox(slider))\n",
    "    curdoc().clear()\n",
    "    curdoc().add_root(layout)\n",
    "    \n",
    "    # Update the data\n",
    "    geosource.geojson = new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input geojson source that contains features for plotting for:\n",
    "# initial year 2018 and initial criteria sale_price_median\n",
    "geosource = GeoJSONDataSource(geojson = json_data)\n",
    "input_field = 'Price'\n",
    "\n",
    "# Define a sequential multi-hue color palette. Red color for Prague city color.\n",
    "palette = brewer['Reds'][8]\n",
    "\n",
    "# Reverse color order so that dark blue is highest obesity.\n",
    "palette = palette[::-1]\n",
    "\n",
    "# Add hover tool\n",
    "hover = HoverTool(tooltips = [ ('Neighborhood','@NAZEV_MC'),\n",
    "                              ('Average Price', '@Price'),\n",
    "                              ('Median Price', '@Median_price'),\n",
    "                              ('Average m2', '@m2'),\n",
    "                              ('Price per Square Metre', '@Avg_m2')])\n",
    "\n",
    "# Call the plotting function\n",
    "p = make_plot(input_field)\n",
    "# Make a slider object: slider \n",
    "#slider = Slider(title = 'Year',start = 2009, end = 2018, step = 1, value = 2018)\n",
    "#slider.on_change('value', update_plot)\n",
    "\n",
    "# Make a selection object: select\n",
    "select = Select(title='Select Criteria:', value='Price', options=['Price', 'Median Price',\n",
    "                                                                               'Price per Square Metre'])\n",
    "select.on_change('value', update_plot)\n",
    "\n",
    "# Make a column layout of widgetbox(slider) and plot, and add it to the current document\n",
    "# Display the current document\n",
    "layout = column(p, widgetbox(select))\n",
    "#layout = column(p, widgetbox(select), widgetbox(slider))\n",
    "curdoc().add_root(layout)\n",
    "\n",
    "output_notebook()\n",
    "show(p)\n",
    "\n",
    "#bokeh serve --show Downloader.ipynb -after streamlining the code for full functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What needs to be done\n",
    "1. Save HTML of sites into a dict, not into a text string with BREAKHERE as delimiter\n",
    "2. Fix relative path for files - my usage of MAC ducked up the file storing locations. This will be more complicated - we need to slice the code into multiple .py files and then import the functions/files from outside either as files or as libraries. Generally, we should have one .py file for Downloader, one for Geocoding, and one for Visualizer. All data (downloaded or created) should be stored within the project repository in a folder called Data. This was functioning on my PC but my MAC killed the relative path storage :/\n",
    "3. Fix str(item) to r''\n",
    "4. Streamline the code - what can be written as a function, should be a function\n",
    "5. Maybe improve Class syntax - not necessary\n",
    "6. Figure out a way how to store and load data consecutively - so we can introduce a slider into the graph where a person could see average prices across times of his choosing (not a priority)\n",
    "    - for this, maybe look into SQL databases lecture\n",
    "    - main idea - download data everyday, save them then based on the date of download. Right now the code is only a snapshot of any given time\n",
    "7. Nominatim allows only 1 request per second for geocoding. Therefore, the process takes many hours. Figure out a way - google? - of shortening this.\n",
    "8. Add popus to the folium_map to include apartment info (price, address, etc.)\n",
    "9. Other data included in the interactive graph? Currently only price, median price, price/m2\n",
    "10. Streamline/write better code anywhere where legit\n",
    "11. Put the Visualizer.py on a web. It's quite easy to put it on a local server, simply by running bokeh serve --show Visualizer.ipynb. This is also a reason for slicing the code. \n",
    "12. Why does one get data fct , printing descrips and one printing apartments?\n",
    "13. delete duplicates which are exactly the same , or delete if they are same in size, street, m2 and Total Price (=highly likely that they are same)?\n",
    "\n",
    "Data output:\n",
    " - source_links.txt - file with htmls from real estate webs\n",
    " - source.json - parsed apartment data from htmls\n",
    " - geo_df.pkl - geocoded addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
